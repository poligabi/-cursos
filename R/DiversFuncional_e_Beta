#####################################
########### AULA 1 Jean Ortega	# 
########### Diversidade Funcional	#
#####################################

library(ade4);library(FD);library(vegan);library(cluster);
library(picante);library(ape)

setwd("C:/R/EcoComunidades")

########################################
#Tarefa 1: Importar o conjunto de dados#
########################################
#Importe as duas planilhas do conjunto de dados "tus"
#Esses dados sao os disponiveis no pacote FD "tussock", confira o que sao com a funcao "?"


#Importe as duas planilhas do conjunto de dados "avi"
#Esses dados sao os disponiveis no pacote ade4 "aviurba", confira o que sao com a funcao "?"

tus_ab<-read.csv("tus_abun.csv", header=T, row.names=1)
tus_tra<-read.csv("tus_traits.csv", header=T, row.names=1)
abu_ab<-read.csv("avi_abun.csv", header=T, row.names=1)
avi_am<-read.csv("avi_ambi.csv", header=T)
avi_tra<-read.csv("avi_traits.csv", header=T, row.names=1)

#######################################
#Tarefa 2: Explorar conjuntos de dados#
#######################################

head(tus_tra)
str(tus_tra)
str(tus_ab)
table(avi_tra$) #sumariza dados categoricos

# Para analises funcionais (e filogeneticas) no R eh interessante que os tracos tenham os nomes das especies a que se referem, 
#que a planilha de abundancia tenham os mesmos nomes nas colunas e que estejam na mesma ordem
# Cheque se os nomes das linhas da coluna de tracos e das colunas da planilha de abundacia coincidem. 
#Para isso use o teste logico "==" e as funcoes "rownames" e "colnames"

rownames(tus_tra) == colnames(tus_ab) 
#para poder integrar as tabelas localxsp com spxtracos 
#as linhas com nomes d sp de uma deve ser = as colunas com nome d sp da outra

#############################################
#Tarefa 3: Estimativa de indices univariados#
#############################################

####### Riqueza de grupos funcionais

tus_tra$dispersal 	#Vamos utilizar somente um traco (p.e. "dispersal" do conjunto tus) para calcular

#Em cada amostra so consideraremos as especies que ocorrem nessa amostra, logo descartaremos especies com abundancia igual a zero.
#Para a comunidade 1 podemos retirar especies com zero segundo esse comando: 
filtro <- tus_ab[1, tus_ab[1,] > 0] 
# seleciona a comunidade da primeira linha =1
# e as colunas com abund >0

#Apos isso, teremos que selecionar somente os tracos dessas especies filtradas. 
#Podemos fazer isso uma vez que ambas as linhas (matriz de tracos) e colunas (matriz de composicao) tem o mesmo nome
tracos_filtro<-tus_tra[names(filtro),] # nessa planilha sp sao linhas, e selecionamos as sp filtradas

tracos_filtro <- tus_tra[names(filtro), ]

#Por fim, somamos quantas estrategias reprodutivas existem nessa comunidade: 
S <- sum(ifelse(table(tracos_filtro$dispersal)>0,yes = 1,no = 0))


#Ok! Isso funcionou para a primeira amostra. 
### Agora vamos automatizar!!!

#Crie um objeto numerico vazio (funcao "numeric") para guardar os valores (tem que ter o mesmo comprimento do numero de amostras)
S_grupoFun <- numeric(nrow(tus_ab))

#Para fazermos para as demais um laco "for" e necessario para facilitar o processo: for(i in 1:length(S_grupoFun)){...}
for(i in 1:length(S_grupoFun)){
  filtro <- tus_ab[i, (tus_ab[i,] > 0)] #Filtre a matriz de composicao somente para as especies com abundancia maior que zero
  tracos_filtro <- tus_tra[names(filtro), ]#Filtre a matriz de traco para somente as especies com abundancia maior que zero
  
  S_grupoFun[i] <- sum(ifelse(table(tracos_filtro$dispersal)>0,yes = 1,no = 0)) 
#Some o numero de tracos reprodutivos e salve no objeto "S_grupoFun" (note o indexador "i")
}
names(S_grupoFun)<-rownames(tus_ab)#De nomes aos valores de "S_grupoFun" (os mesmos nomes das amostras)
S_grupoFun

########## Media e SD

#Precisaremos da mesma logica de filtros aqui tambem. Por que?
media_tracos <-(numeric(nrow(tus_ab))) #Crie um objeto numerico vazio para guardar os valores de medias e outro para os SD
sd_tracos <- (numeric(nrow(tus_ab)))

filtro <- tus_ab[1, tus_ab[1,] > 0] 
tracos_filtro <- tus_tra[names(filtro), ]

#A media e SD precisam de tracos continuos, logo mude "dispersal" para "height"
S <- sum(ifelse(table(tracos_filtro$height)>0,yes = 1,no = 0))

for(i in 1:length(media_tracos)){
  filtro <- tus_ab[i, (tus_ab[i,] > 0)] #Filtre a matriz de composicao somente para as especies com abundancia maior que zero
  tracos_filtro <- tus_tra[names(filtro), ]#Filtre a matriz de traco para somente as especies com abundancia maior que zero
  media_tracos[i]<-mean(tracos_filtro$height, #Estime e salve a media de "height" para a comunidade "i" 
		na.rm=T) # desconsidera se houver célular com NA
  sd_tracos[i]<-sd(tracos_filtros$height, na.rm=T)  #Faca o mesmo para "sd_tracos"
		# [i] = salva valores na posição i
}
names(media_tracos)<-rownames(tus_ab) #Nomeie as medias
names(sd_tracos)<-rownames(tus_ab) #Nomeie os SDs

########### Media ponderada (CWM - Community weighted mean)

#Para a CWM, precisamos alem de filtrar estimar os pesos, as abundancias relativas
cwm_tracos <-numeric(nrow(tus_ab)) #Crie um objeto numerico vazio para guardar os valores de medias ponderadas

for(i in 1:length(cwm_tracos)){
	filtro <- tus_ab[i, (tus_ab[i,] > 0)]#Filtre a matriz de composicao somente para as especies com abundancia maior que zero
  tracos_filtro <- tus_tra[names(filtro), ]#Filtre a matriz de traco para somente as especies com abundancia maior que zero
  pesos<-filtro/sum(filtro) #Crie um vetor de abundancias relativas, divida cada valor pelo somatorio ("sum")
  cwm_tracos[i]<-weighted.mean(x=tracos_filtro$height, w= pesos) #Estime e salve a media ponderada (funcao "weighted.mean") de "height" para a comunidade "i"
}

names(cwm_tracos)<-rownames(tus_ab) #Nomeie os resultados
cwm_tracos




###############################################
#Tarefa 4: Estimativa de indices multivariados#
###############################################

############ Atributo de diversidade funcional (FAD)

FAD_comu <-numeric(nrow(tus_ab)) #Crie um objeto numerico vazio para guardar os valores de FAD

for(i in 1:length(FAD_comu)){
   filtro <- tus_ab[i, (tus_ab[i,] > 0)]#Filtre a matriz de composicao somente para as especies com abundancia maior que zero
   tracos_filtro <- tus_tra[names(filtro), ]#Filtre a matriz de traco para somente as especies com abundancia maior que zero
   dis_comu<-daisy(tracos_filtro,metric="gower")#Calcule uma matriz de dissimilaridade de Gower com o conjunto de tracos de "tus". 
#Para isso utilize a funcao "daisy" do pacote "cluster".
     FAD_comu[i]<- sum(dis_comu) #Calcule a media das dissimilaridades
}
 names(FAD_comu)<- rownames(tus_ab)#Nomeie os resultados

######### Diversidade funcional (FD)

FD_comu <- numeric(nrow(tus_ab))#Crie um objeto numerico vazio para guardar os valores de FAD

for(i in 1:length(FD_comu)){
   filtro <- tus_ab[i, (tus_ab[i,] > 0)]#Filtre a matriz de composicao somente para as especies com abundancia maior que zero
   tracos_filtro <- tus_tra[names(filtro), ]#Filtre a matriz de traco para somente as especies com abundancia maior que zero
    dis_comu<-daisy(tracos_filtro,metric="gower")#Calcule uma matriz de dissimilaridade de Gower com o conjunto de tracos de "tus". 
#Para isso utilize a funcao "daisy" do pacote "cluster".
   agrup_comu<- hclust(d= dis_comu, method="average")#Construa um dendograma com a matriz de dissimilaridade (funcao "hclust" do pacote "stats")
   #d= matriz d dist dissimilaridade
   agrup_comu<-as.phylo(agrup_comu) #"Force" o R a entender o dendograma como um cladograma (funcao "as.phylo" do pacote "ape")
  
  FD_comu[i]<-sum(agrup_comu$edge.lenght)#Por fim, some os comprimentos de ramos "NOME_OBJETO$edge.length" e salve como "FD_comu"
}
names(FD_comu)<-rownames(tus_ab) #Nomeie os resultados

###########
#Todos os indices abaixo podem ser calculados utilizando a funcao "dbFD", veja o help dela
#Para facilitar utilize os argumentos padroes da "dbFD". 
#Calcule a diversidade funcional para os conjuntos de dados "avi" e "tus"

dbFD_tus<-dbFD(x= tus_tra, a=tus_ab, corr="lingoes") #corr=metodo p corrigir dados nao euclideanos
names(dbFD_tus) #nomes dos dados gerados p ser chamado

### Q de Rao
dbFD_tus$RaoQ

#Riqueza funcional (FRic)
dbFD_tus$

#Divergencia funcional (FDiv)
dbFD_tus$

#Dispersao funcional (FDis)
dbFD_tus$

#Equitabilidade funcional (FEve)
dbFD_tus$

dbFD_avi<-dbFD(x= avi_tra, a=avi_ab, corr="lingoes") #corr=metodo p corrigir dados nao euclideanos

##############################################################
#Tarefa 5: Avalie a correlacao entre os indices multivariados#
##############################################################
#Junte os indices em um data.frame
FD_avi<-data.frame(RaoQ = dbFD_avi$RaoQ,FRic = dbFD_avi$FRic,
                   FDis = dbFD_avi$FDis, #nao calcula FDiv com dados categoricos
                   FEve = dbFD_avi$FEve)
boxplot(FD_avi)

#Calcule uma matriz de correlacao entre os indices
cor(FD_avi)

#Exporte o data frame com os indices

#########################
### AULA 2 Jean Ortega	#
### Diversidade Beta	#
#########################

library(vegan); library(betapart)

########################################
#Tarefa 1: Importar o conjunto de dados#
########################################
#Importe as tres planilhas do conjunto de dados "mite"
setwd("C:/R/EcoComunidades")

mite_ab<-read.csv("mite_ab.csv", header=T)
mite_am<-read.csv("mite_ambi.csv", header=T)
mite_co<-read.csv("mite_coords.csv", header=T)

#Esses dados sao os disponiveis no pacote FD "mite", confira o que sÃ£o com a funcao "?"

#######################################
#Tarefa 2: Explorar conjuntos de dados#
#######################################
#Veja um resumo dos dados de composicao com a funcao "summary"
summary(mite_ab)

#Uma exploracao interessante e uma medida agregada entre as amostras (como riqueza ou abundancia total).
#E util para checar a presenca de NAs e amostras com zero (isso e importante para alguns indices de dissimilaridade).
#Para isso utilize a funcao "rowSums"
rowSums(mite_ab)

############################################################
#Tarefa 3: Estimativa de indices de DB por dissimilaridades#
############################################################
#Transforme os dados de mite em presenca e ausencia
mite_pa<-ifelse(test= mite_ab>0, yes=1, no=0)
head(mite_pa)
#Varias funcoes no pacote vegan calculam diferentes indices de diversidade beta

#Diversidade Beta de Whittaker (DBW):
#Calcule a riqueza por amostra de "mite_pa" (rowSums)
S<-rowSums(mite_pa)

#Estime alfa medio, diversidade local media
alfa_medio<- mean(S)

#Estime gama ("ncol"), ncoluna = nsp totais = diversidade regional/gama
div_gama<- ncol(mite_pa)

#Estime DBW (diversidade beta de whitakker) para todo o conjunto mite
div_gama/alfa_medio
(div_gama/alfa_medio)-1

#O DBW pode ser calculado alternativamente par-a-par utilizando a funcao "betadiver"
#Calcule e salve o indice DBW
DBW<- betadiver(mite_pa, method="w")
DBW

#DB Jaccard, Sorensen e Bray-Curtis:
#Esses indices de dissimilaridade podem ser calculados com a funcao "vegdist"
#Calcule e salve a DB estimada com as diferentes dissimilaridades (valor medio de cada indice)
DBJ<- vegdist(mite_pa, method="jaccard", binary=T)
DBS<- vegdist(mite_pa, method="bray", binary=T) #sorensen
DBBC<- vegdist(mite_ab, method="bray", binary=F) #bray-curtis

plot(DBJ, DBS)#relaciona as diversidades dos dados de presencaxausencia = linear
plot(DBS, DBBC)

#DB por Raup-Crick (DBRC)
#A DBRC esta implementada no vegan com a abordagem de Chase et al. (2011) na funcao "raupcrick" (note que a dissimilaridade de Raup-Crick tambem esta no vegdist, mas sem o modelo nulo)
DBRC<-raupcrick(comm=mite_pa, nsimul=999)
plot(DBJ, DBRC) #cada plot diferente, por ser baseado em simulacoes

#Vamos construir um modelo nulo para estimar se a composicao e mais diferente (positivo) ou mais similar (negativo) do que esperado ao acaso
#A maioria dos modelos nulos em ecologia estao no vegan na suncao oecosimu
resu_MN_mite <- oecosimu(comm=mite_pa, method="r1", 
			nestfun=function(x)mean(vegdist(x, method="jaccard", binary=T)))
#DBRC com modelo nulo "r1": probabilidade de reamostrar as especies proporcionais as suas ocorrencias observadas
#nestfun = metrica

hist(resu_MN_mite$oecosimu$simulated, xlim=c(0.55,.7)) #media dos indices d jaccar em cada uma das matrizes simuladas
abline(v=mean(DBJ)) #resultado foi menor doq observado nas matrizes ao acaso (modelo nulo)
#A composicao e mais diferente ou similar do que esperado ao acaso?
#se esta abaixo, elas são +similares doq esperado ao acaso

########################################################
#Tarefa 3: Estimativa de indices de DB por distancia ao#
#		centroide e LCBD					 #
########################################################

#DB distancia ao centroide (DBcent)
#Para a distancia ao centroide e necessario um fator. Vamos calcular a distancia ao centroide em relacao ao fator "Shrub" da planilha "mite_ambi". Vamos utilizar a distancia de Bray-Curtis
#Cheque os resultados
names(mite_am) #"SubsDens"  "WatrCont"  "Substrate" "Shrub" "Topo" "Site"  "Forest"    "Region" 

Dcent<-betadisper(d=DBBC, group=mite_am$Shrub)
plot(Dcent)

#A distancia ao centroide e diretamente associada a um teste de hipotese, logo, utilize a funcao "anova" para ver um resumo do teste
#A distancia de cada amostra para o centroide pode ser acessada com NOME_OBJETO$distances
#Plote as distancias ao centroide


#Variancia total de matrizes (BD_Total):
#Carregue a funcao "beta.div" no script "LCBD_Legendre & De Caceres 2013_Ecol Lett.r"
#Calcule e salve a BD_Total para o conjunto mite

BDT<-beta.div(Y=mite_ab) #SCBD=quanto cada sp.contribui p variancia total=diversid beta
#LCBD = quanto cada amostra constribui p variancia total=divers beta

#Uma caracteristica interessante da BD_Total e a decomposicao das contribuicoes locais (LCBD)
#A LCBD propriamente pode ser acessada com NOME_OBJETO$LCBD

#Podemos criar um mapa com isso
plot(x = mite_co$x, y = mite_co$y,type = "n")#Plote as coordenadas das amostras (planilha "mite_coords")
points(x = mite_co$x, y = mite_co$y,cex = BDT$LCBD*200)



#Por fim exporte o objeto da LCBD (iremos utilizar adiante)
LCBD<-BDT$LCBD

##################################### script "LCBD_Legendre & De Caceres 2013_Ecol Lett.r" ###############################

beta.div <- function(Y, method="hellinger", sqrt.D=FALSE, samp=TRUE, nperm=999, save.D=FALSE, clock=FALSE)
  #
  # Compute estimates of total beta diversity as the total variance in Y, 
  # for 20 dissimilarity coefficients or analysis of raw data (not recommended). 
  # LCBD indices are tested by permutation within columns of Y.
  # This version includes direct calculation of the Jaccard, Sorensen and Ochiai 
  # coefficients for presence-absence data.
  #
  # Arguments --
  # 
  # Y : community composition data matrix.
  # method : name of one of the 20 dissimilarity coefficients, or "none" for
#          direct calculation on Y (also the case with method="euclidean").
# sqrt.D : If sqrt.D=TRUE, the distances in matrix D are square-rooted before 
#          computation of SStotal, BDtotal and LCBD. 
# samp : If samp=TRUE, the abundance-based distances (ab.jaccard, ab.sorensen,
#        ab.ochiai, ab.simpson) are computed for sample data. If samp=FALSE, 
#        they are computed for true population data.
# nperm : Number of permutations for test of LCBD.
# save.D : If save.D=TRUE, the distance matrix will appear in the output list.
# clock : If clock=TRUE, the computation time is printed in the R console.
#
# License: GPL-2 
# Author:: Pierre Legendre, December 2012, April-May 2013
{
  ### Internal functions
  centre <- function(D,n)
    # Centre a square matrix D by matrix algebra
    # mat.cen = (I - 11'/n) D (I - 11'/n)
  {	One <- matrix(1,n,n)
  mat <- diag(n) - One/n
  mat.cen <- mat %*% D %*% mat
  }
  ###
  BD.group1 <- function(Y, method, save.D, per)
  {
    if(method=="profiles") Y = decostand(Y, "total")
    if(method=="hellinger") Y = decostand(Y, "hellinger")
    if(method=="chord") Y = decostand(Y, "norm")
    if(method=="chisquare") Y = decostand(Y, "chi.square")
    #
    s <- scale(Y, center=TRUE, scale=FALSE)^2   # eq. 1
    SStotal <- sum(s)          # eq. 2
    BDtotal <- SStotal/(n-1)   # eq. 3
    if(!per) { SCBD<-apply(s,2,sum)/SStotal }else{ SCBD<-NA }  # eqs. 4a and 4b
    LCBD <- apply(s, 1, sum)/SStotal  # eqs. 5a and 5b
    #
    D <- NA
    if(!per & save.D)   D <- dist(Y)
    #
    out <- list(SStotal_BDtotal=c(SStotal,BDtotal), SCBD=SCBD, LCBD=LCBD, 
                method=method, D=D)
  }
  ###
  BD.group2 <- function(Y, method, sqrt.D)
  {
    if(method == "divergence") {
      D = D11(Y)		
      
    } else if(any(method == 
                  c("jaccard","sorensen","ochiai"))) 
    {
      if(method=="jaccard") D = dist.binary(Y, method=1) # ade4 takes sqrt(D)
      if(method=="sorensen")  D = dist.binary(Y, method=5) #ade4 takes sqrt(D)
      if(method=="ochiai") D = dist.binary(Y, method=7) # ade4 takes sqrt(D)
      
    } else if(any(method == 
                  c("manhattan","canberra","whittaker","percentagedifference","wishart"))) 
    {
      if(method=="manhattan") D = vegdist(Y, "manhattan")
      if(method=="canberra")  D = vegdist(Y, "canberra")
      if(method=="whittaker") D = vegdist(decostand(Y,"total"),"manhattan")/2
      if(method=="percentagedifference") D = vegdist(Y, "bray")
      if(method=="wishart")   D = WishartD(Y)
    } else {
      if(method=="modmeanchardiff") D = D19(Y)
      if(method=="kulczynski")  D = vegdist(Y, "kulczynski")
      if(method=="ab.jaccard")  D = chao(Y, coeff="Jaccard", samp=samp)
      if(method=="ab.sorensen") D = chao(Y, coeff="Sorensen", samp=samp)
      if(method=="ab.ochiai")   D = chao(Y, coeff="Ochiai", samp=samp)
      if(method=="ab.simpson")  D = chao(Y, coeff="Simpson", samp=samp)
    }
    #
    if(sqrt.D) D = sqrt(D)
    SStotal <- sum(D^2)/n      # eq. 8
    BDtotal <- SStotal/(n-1)   # eq. 3
    delta1 <- centre(as.matrix(-0.5*D^2), n)   # eq. 9
    LCBD <- diag(delta1)/SStotal               # eq. 10b
    #
    out <- list(SStotal_BDtotal=c(SStotal,BDtotal), LCBD=LCBD, 
                method=method, D=D)
  }
  ###
  ###
  method <- match.arg(method, c("euclidean", "manhattan", "modmeanchardiff", "profiles", "hellinger", "chord", "chisquare", "divergence", "canberra", "whittaker", "percentagedifference", "wishart", "kulczynski", "ab.jaccard", "ab.sorensen","ab.ochiai","ab.simpson","jaccard","sorensen","ochiai","none"))
  #
  if(any(method == c("profiles", "hellinger", "chord", "chisquare", "manhattan", "modmeanchardiff", "divergence", "canberra", "whittaker", "percentagedifference", "kulczynski"))) require(vegan)
  if(any(method == c("jaccard","sorensen","ochiai"))) require(ade4)
  #
  if(is.table(Y)) Y <- Y[1:nrow(Y),1:ncol(Y)]    # In case class(Y) is "table"
  n <- nrow(Y)
  #
  aa <- system.time({
    if(any(method == 
           c("euclidean", "profiles", "hellinger", "chord", "chisquare","none"))) {
      note <- "Info -- This coefficient is Euclidean"
      res <- BD.group1(Y, method, save.D, per=FALSE)
      #
      # Permutation test for LCBD indices, distances group 1
      if(nperm>0) {
        p <- ncol(Y)
        nGE.L = rep(1,n)
        for(iperm in 1:nperm) {
          Y.perm = apply(Y,2,sample)
          res.p <- BD.group1(Y.perm, method, save.D, per=TRUE)
          ge <- which(res.p$LCBD >= res$LCBD)
          nGE.L[ge] <- nGE.L[ge] + 1
        }
        p.LCBD <- nGE.L/(nperm+1)
      } else { p.LCBD <- NA }
      #
      if(save.D) { D <- res$D } else { D <- NA }
      #
      out <- list(SStotal_BDtotal=res$SStotal_BDtotal, SCBD=res$SCBD, 
                  LCBD=res$LCBD, p.LCBD=p.LCBD, method=method, note=note, D=D)
      
    } else {
      #
      if(method == "divergence") {
        note = "Info -- This coefficient is Euclidean"
      } else if(any(method == c("jaccard","sorensen","ochiai"))) {
        note = c("Info -- This coefficient is Euclidean because dist.binary ",
                 "of ade4 computes it as sqrt(D). Use beta.div with option sqrt.D=FALSE")
      } else if(any(method == 
                    c("manhattan","canberra","whittaker","percentagedifference","wishart"))) {
        if(sqrt.D) {
          note = "Info -- This coefficient, in the form sqrt(D), is Euclidean"
        } else {
          note = c("Info -- For this coefficient, sqrt(D) would be Euclidean", 
                   "Use is.euclid(D) of ade4 to check Euclideanarity of this D matrix")
        }
      } else {
        note = c("Info -- This coefficient is not Euclidean", 
                 "Use is.euclid(D) of ade4 to check Euclideanarity of this D matrix")
      }
      #
      res <- BD.group2(Y, method, sqrt.D)
      #
      # Permutation test for LCBD indices, distances group 2
      if(nperm>0) {
        nGE.L = rep(1,n)
        for(iperm in 1:nperm) {
          Y.perm = apply(Y,2,sample)
          res.p <- BD.group2(Y.perm, method, sqrt.D)
          ge <- which(res.p$LCBD >= res$LCBD)
          nGE.L[ge] <- nGE.L[ge] + 1
        }
        p.LCBD <- nGE.L/(nperm+1)
      } else { p.LCBD <- NA }
      #
      if(sqrt.D) note.sqrt.D<-"sqrt.D=TRUE"  else  note.sqrt.D<-"sqrt.D=FALSE"
      if(save.D) { D <- res$D } else { D <- NA }
      #
      out <- list(SStotal_BDtotal=res$SStotal_BDtotal, LCBD=res$LCBD,  
                  p.LCBD=p.LCBD, method=c(method,note.sqrt.D), note=note, D=D)
    }
    #
  })
  aa[3] <- sprintf("%2f",aa[3])
  if(clock) cat("Time for computation =",aa[3]," sec\n")
  #
  class(out) <- "beta.div"
  out
}

D11 <- function(Y, algo=1)
  #
  # Compute Clark's coefficient of divergence. 
  # Coefficient D11 in Legendre and Legendre (2012, eq. 7.51).
  #
  # License: GPL-2 
  # Author:: Pierre Legendre, April 2011
{
  Y <- as.matrix(Y)
  n <- nrow(Y)
  p <- ncol(Y)
  # Prepare to divide by pp = (p-d) = no. species present at both sites
  Y.ap <- 1 - decostand(Y, "pa")
  d <- Y.ap %*% t(Y.ap)
  pp <- p-d   # n. species present at the two compared sites
  #
  if(algo==1) {   # Faster algorithm
    D <- matrix(0, n, n)
    for(i in 2:n) {
      for(j in 1:(i-1)) {
        num <- (Y[i,]-Y[j,])
        den <- (Y[i,]+Y[j,])
        sel <- which(den > 0)
        D[i,j] = sqrt(sum((num[sel]/den[sel])^2)/pp[i,j])
      }
    }
    #
  } else {   # Slower algorithm 
    D <- matrix(0, n, n)
    for(i in 2:n) {
      for(j in 1:(i-1)) {
        temp = 0
        for(p2 in 1:p) {
          den = Y[i,p2] + Y[j,p2]
          if(den > 0) {
            temp = temp + ((Y[i,p2] - Y[j,p2])/den)^2
          }
        }
        D[i,j] = sqrt(temp/pp[i,j])
      }
    }
    #
  }	
  DD <- as.dist(D)
}

D19 <- function(Y)
  #
  # Compute the Modified mean character difference.
  # Coefficient D19 in Legendre and Legendre (2012, eq. 7.46).
  # Division is by pp = number of species present at the two compared sites
  #
  # License: GPL-2 
  # Author:: Pierre Legendre, April 2011
{
  Y <- as.matrix(Y)
  n <- nrow(Y)
  p <- ncol(Y)
  # Prepare to divide by pp = (p-d) = n. species present at both sites
  Y.ap <- 1 - decostand(Y, "pa")
  d <- Y.ap %*% t(Y.ap)
  pp <- p-d   # n. species present at the two compared sites
  #
  D <- vegdist(Y, "manhattan")
  DD <- as.dist(as.matrix(D)/pp)
}

WishartD <- function(Y)
  #
  # Compute dissimilarity - 1 - Wishart similarity ratio (Wishart 1969).
  #
  # License: GPL-2 
  # Author:: Pierre Legendre, August 2012
{
  CP = crossprod(t(Y))
  SS = apply(Y^2,1,sum)
  n = nrow(Y)
  mat.sq = matrix(0, n, n)
  for(i in 2:n) {
    for(j in 1:(n-1)) { mat.sq[i,j] = CP[i,j]/(SS[i] + SS[j] - CP[i,j]) }
  }
  mat = 1 - as.dist(mat.sq)
}

chao <- function(mat, coeff="Jaccard", samp=TRUE)
  #
  # Compute Chao et al. (2006) abundance-based indices.
  #
  # Arguments -
  # mat = data matrix, species abundances
  # coef = "Jaccard" : modified abundance-based Jaccard index
  #        "Sorensen": modified abundance-based SÃ¸rensen index
  #        "Ochiai"  : modified abundance-based Ochiai index
  #        "Simpson" : modified abundance-based Simpson index
  # samp=TRUE : Compute dissimilarities for sample data
  #     =FALSE: Compute dissimilarities for true population data
#
# Details -
# For coeff="Jaccard", the output values are identical to those
# produced by vegan's function vegdist(mat, "chao").
#
# Help received from A. Chao and T. C. Hsieh in July 2012 for the computation  
# of dissimilarities for true population data is gratefully acknowledged.
#
# Reference --
# Chao, A., R. L. Chazdon, R. K. Colwell and T. J. Shen. 2006. 
# Abundance-based similarity indices and their estimation when there 
# are unseen species in samples. Biometrics 62: 361â€“371.
#
# License: GPL-2 
# Author:: Pierre Legendre, July 2012
{
  require(vegan)
  nn = nrow(mat)
  res = matrix(0,nn,nn)
  if(samp) {   # First for sample data
    for(k in 2:nn) {
      for(j in 1:(k-1)) {
        #cat("k =",k,"  j =",j,"\n")
        v1 = mat[j,]   # Vector 1
        v2 = mat[k,]   # Vector 2
        v1.pa = decostand(v1,"pa")   # Vector 1 in presence-absence form
        v2.pa = decostand(v2,"pa")   # Vector 2 in presence-absence form
        N.j = sum(v1)   # Sum of abundances in vector 1
        N.k = sum(v2)   # Sum of abundances in vector 2
        shared.sp = v1.pa * v2.pa   # Vector of shared species ("pa")
        if(sum(shared.sp) == 0) { 
          res[k,j] = 1
        } else {
          C.j = sum(shared.sp * v1)   # Sum of shared sp. abundances in v1
          C.k = sum(shared.sp * v2)   # Sum of shared sp. abundances in v2
          # a1.j = sum(shared.sp * v1.pa)
          # a1.k = sum(shared.sp * v2.pa)
          a1.j = length(which((shared.sp * v2) == 1)) # Singletons in v2
          a1.k = length(which((shared.sp * v1) == 1)) # Singletons in v1
          a2.j = length(which((shared.sp * v2) == 2)) # Doubletons in v2
          if(a2.j == 0) a2.j <- 1
          a2.k = length(which((shared.sp * v1) == 2)) # Doubletons in v1
          if(a2.k == 0) a2.k <- 1
          # S.j = sum(v1[which(v2 == 1)]) # Sum abund. in v1 for singletons in v2
          # S.k = sum(v2[which(v1 == 1)]) # Sum abund. in v2 for singletons in v1
          sel2 = which(v2 == 1)
          sel1 = which(v1 == 1)
          if(length(sel2)>0) S.j = sum(v1[sel2]) else S.j = 0
          if(length(sel1)>0) S.k = sum(v2[sel1]) else S.k = 0
          
          U.j = (C.j/N.j) + ((N.k-1)/N.k) * (a1.j/(2*a2.j)) * (S.j/N.j) # Eq. 11
          if(U.j > 1) U.j <- 1
          U.k = (C.k/N.k) + ((N.j-1)/N.j) * (a1.k/(2*a2.k)) * (S.k/N.k) # Eq. 12
          if(U.k > 1) U.k <- 1
          
          if(coeff == "Jaccard") {                     # "Jaccard"
            res[k,j] = 1 - (U.j*U.k/(U.j + U.k - U.j*U.k))
          } else if(coeff == "Sorensen") {         # "Sorensen"
            res[k,j] = 1 - (2*U.j*U.k/(U.j + U.k))
          } else if(coeff == "Ochiai") {           # "Ochiai"
            res[k,j] = 1 - (sqrt(U.j*U.k))
          } else if(coeff == "Simpson") { 
            # Simpson (1943), or Lennon et al. (2001) in Chao et al. (2006)
            res[k,j] = 1 -
              (U.j*U.k/(U.j*U.k+min((U.j-U.j*U.k),(U.k-U.j*U.k))))
          } else { # 
            stop("Incorrect coefficient name")
          }
        }
      }
    }
    
  } else {   # Now for complete population data
    
    for(k in 2:nn) {
      for(j in 1:(k-1)) {
        v1 = mat[j,]   # Vector 1
        v2 = mat[k,]   # Vector 2
        v1.pa = decostand(v1,"pa")   # Vector 1 in presence-absence form
        v2.pa = decostand(v2,"pa")   # Vector 2 in presence-absence form
        shared.sp = v1.pa * v2.pa    # Vector of shared species ("pa")
        if(sum(shared.sp) == 0) { 
          res[k,j] = 1
        } else {
          N1 = sum(v1)   # Sum of abundances in vector 1
          N2 = sum(v2)   # Sum of abundances in vector 2
          U = sum(shared.sp * v1)/N1   # Sum of shared sp. abundances in v1
          V = sum(shared.sp * v2)/N2   # Sum of shared sp. abundances in v2
          
          if(coeff == "Jaccard") {                     # "Jaccard"
            res[k,j] = 1 - (U*V/(U + V - U*V))
          } else if(coeff == "Sorensen") {         # "Sorensen"
            res[k,j] = 1 - (2*U*V/(U + V))
          } else if(coeff == "Ochiai") {           # "Ochiai"
            res[k,j] = 1 - (sqrt(U*V))
          } else if(coeff == "Simpson") { # "Simpson"
            res[k,j] = 1 - (U*V/(U*V+min((U-U*V),(V-U*V)))) # Eq. ?
          } else { # 
            stop("Incorrect coefficient name")
          }
        }
      }
    }
  }
  res <- as.dist(res)
}
######## End of beta.div function


#########################
### AULA 3 Jean Ortega	#
### Diversidade Beta	#
#########################

library(betapart);library(vegan)

########################################
#Tarefa 1: Importar o conjunto de dados#
########################################
#Importe as planilhas "mite_ab" e "mite_ambi"
setwd("C:/R/EcoComunidades")

mite_ab<-read.csv("mite_ab.csv", header=T)
mite_am<-read.csv("mite_ambi.csv", header=T)
mite_co<-read.csv("mite_coords.csv", header=T)

str(mite_am)
#######################################################
#Tarefa 2: Particao da diversidade beta em componentes#
#######################################################
#Transforme a matriz de abundancias em presenca e ausencia (P/A)
mite_pa<-ifelse(mite_ab>0, yes=1, no=0)

#Particao diversidade em componentes: aninhamento (nestedness) e substituicao (turnover)
#Par-a-par:
#A particao par-a-par e feita na funcao beta.pair do pacote "betapart"
BD_Bas<-beta.pair(x=mite_pa) #usa por def o indice d sorensen

names(BD_Bas) #"beta.sim"=turnover "beta.sne"=nestedness "beta.sor"=beta total
BD_Bas$beta.sim
BD_Bas$beta.sne
BD_Bas$beta.sor

plot(BD_Bas$beta.sor, BD_Bas$beta.sim)
#se fosse so substituição o grafico subiria em uma linha reta
# a parte mostrada representa componente de aninhamento
#Calcule a particao com o conjunto mite P/A


#Particao multi-local:
#A particao multi-local e feita na funcao beta.multi
BD_total<-beta.multi(x=mite_pa)
names(BD_total) #"beta.SIM" "beta.SNE" "beta.SOR"
BD_total$beta.SIM
BD_total$beta.SNE
BD_total$beta.SOR

################################################
#Tarefa 3: Particao aditiva da diversidade beta#
################################################
#Calcule e salve a particao aditiva com as escalas espaciais no conjunto de dados "mite_ambi" 
str(mite_am) #(ultimas tres coluna)
escala_mite<- mite_am[,c(6:8)]

adi_mite<- adipart(y=mite_pa, x= escala_mite, index="richness")
#Veja o resultado
#alpha.1 = menor escala local
#alpha.2= p calcular o primeiro nivel d diversidade beta
#beta.1 = alpha2 - alpha1 = diferença entre 2 locais é maior q
#beta.2 = gama - alpha2 = diferença regional e um local dentro dela (menor) 
#gama= alpha1 + betas(1e2) = divers regional

#########################
### AULA 4 Jean Ortega	#
### Analises		#
#########################

library(ade4);library(FD);library(picante);
library(vegan);library(betapart);library(cluster);
library(ape)

########################################
#Tarefa 1: Importar o conjunto de dados#
########################################
#Importe as duas planilhas do conjunto de dados (indices funcionais e LCBD que voces exportaram, conjunto "mite" e "avi")
setwd("C:/R/EcoComunidades")

mite_ab<-read.csv("mite_ab.csv", header=T)
str(mite_ab)
mite_am<-read.csv("mite_ambi.csv", header=T)
str(mite_am)
mite_co<-read.csv("mite_coords.csv", header=T)
str(mite_co)
LCBD_mite<-read.csv("mite_coords.csv", header=T) #analises aula2 -beta
avi_ab<-read.csv("avi_abun.csv", header=T, row.names=1)
avi_am<-read.csv("avi_ambi.csv", header=T)
str(avi_am)
str(avi_ab)
avi_tra<-read.csv("avi_traits.csv", header=T, row.names=1)
FD_avi<-read.csv("FD_avi.csv") #analises aula1 -funcional

################################
#Tarefa 2: Exploracao dos dados#
################################
#Univariado
#Estatistica descritiva:
#Um resumo rapido de todas as variaveis de uma matriz ou data-frame pode ser obtido com a funcao "summary"
summary(FD_avi)

#Outras estatisticas de interesse podem ser calculadas com a funcao "apply". Calcule o SD para a matriz de indices.
apply(FD_avi[,-1], MARGIN=2, FUN=sd)

boxplot(FD_avi[,-1])
###########################################
#Tarefa 3: Testes de hipoteses univariadas#
###########################################
###Teste t:
#A Equitabilidade funcional pode diferir dependendo do tipo de ambiente (impacto) onde as comunidades estao inseridas
#Faca um teste t da equitatibilidade funcional (FEve; avi) em funcao do tipo de ambiente (avi_ambi$farms)
plot(FD_avi$FEve~avi_am$farms)
t.test(formula=FD_avi$FEve~avi_am$farms)

### ANOVA fatorial
#No conjunto "avi", ha outras categorias de impacto, p.e., presenca de industrias
lm_FEve<-lm(FD_avi$FEve~avi_am$farms * avi_am$industry)
anova(lm_FEve)	#nao teve influencia

###### ANCOVA
#Em alguns casos podemos avaliar hipoteses que envolvem fatores e variaveis continuas em conjunto.
# P.e., podemos pensar que locais com maior quantidade de recurso e heterogeneidade ambiental acomodem o nicho de um maior numero de especies, 
#resultando em maior contribuicao local para a DB
#Construa um modelo de ANCOVA avaliando essa hipotese com os conjuntos de dados LCBD e "mite_ambi" (SubsDens e Shrub)
lm_LCBD_mite<- lm(LCBD_mite$x ~ mite_am$SubsDens * mite_am$Shrub)
anova(lm_LCBD_mite) 	#teve influencia e a interação de ambos foi +influentes q elas sozinha

### Correlacao
 #Na avaliacao da correlacao entre os indices funcionais observamos que RaoQ e FDis eram muito correlacionados no conjunto "avi"
 #Teste se essa correlacao e significativa com "cor.test"
cor(FD_avi[,-1])
cor.test(FD_avi$RaoQ, FD_avi$FDis)

###### Regressao
#Modelos de regressoes lineares podem ser ajustados no R com a funcao "lm"
#Construa um modelo avaliando a hipotese que maior quantidade de recurso (mite_ambi$SubsDens) aumenta a LCBD
#Um resumo do modelo pode ser obtido pela funcao "summary"
lm_mite<-lm(LCBD_mite$x~mite_am$SubsDens)
summary(lm_mite)

#Transforme o conjunto avi_ab em presenca e ausencia
avi_pa<-ifelse(avi_ab[,-1]>0, yes=1, no=0)
#Some as linhas dessa matriz transformada. O que acabamos de estimar?
S_avi<-rowSums(avi_pa)

#Uma relacao peculiar em ecologia funcional e que o aumento da riqueza taxonomica aumenta a riqueza funcional
#Construa um modelo avaliando essa hipotese utilizando a S de "avi" e a FRic
lm_avi<-lm(FD_avi$FRic~S_avi)
summary(lm_avi)

###########################################
#Tarefa 4: Exploracao do conjunto de dados#
###########################################
# MULTIVARIADO
###PCA sobre os indices funcionais
#Uma PCA de correlacao pode ser feita com a funcao "prcomp" utilizando o argumento "scale. = TRUE"
pca_avi<-prcomp(FD_avi,scale.=T)
biplot(pca_avi)	#vetores=indices funcionais



###prof mandara pronto na versao final
autovet <- #Multiplicando as cargas (loadings; NOME_OBJETO$rotation) pelo SD (NOME_OBJETO$sdev) devolvemos as cargas para a escala de correlacoes
autovet
autoval <-  #Usando a funcao "var" junto de "apply" nos escores (NOME_OBJETO$x) estimamos os autovalores
autoval

 #Utilize a funcao biplot para gerar uma ordenacao dos resultados

####### PERMANOVA
#Utilize a PERMANOVA para avaliar a hipotese que comunidades mais heterogeneas apresentarao maior substituicao de especies
#Para isso, utilize o conjunto o fator "mite_ambi$Shrub"
#Construa uma matriz de dissimilaridade par-a-par do componente de substituicao de especies de Baselga (Bsim)
mite_bas<-beta.pair(ifelse(mite_ab>0,1,0))
permanova_mite<- adonis(mite_bas$beta.sim~mite_am$Shrub)

#Qual e a hipotese sendo testada aqui?
permanova_mite

##	PROF FARA GRAFICO
pcoa_mite<-cmdscale() #Podemos representar essas distancias em uma ordenacao PCoA (cmdscale)

cols <- #Crie um vetor de caracteres (funcao "character") que guardara as cores para os simbolos do grafico

for(i in 1:length(cols)){ #Esse laco "for" esta avaliando qual grupo de "Shrub" cada observacao pertence e atribuindo um valor ("red", "blue" ou "black")
  if(mite_ambi$Shrub[i] == "None"){
    cols[i] <- "red"
  }
  if(mite_ambi$Shrub[i] == "Few"){
    cols[i] <- "blue"
  }
  if(mite_ambi$Shrub[i] == "Many"){
    cols[i] <- "black"
  }
}

plot() #Construa a ordenacao com a funcao "plot"

###### PERMDisp
#Uma hipotese correlata a testada na PERMANOVA e que comunidades mais heterogeneas apresentam maiores distancias aos centroides (diversidade beta)
#Avalie essa hipotese com a PERMDisp (funcao "betadisper") com a matriz do componente de substituicao de especies e o fator "mite_ambi$Shrub"
permdisp_mite<- betadisper(d= mite_bas$beta.sim, group= mite_am$Shrub)
	#d= matriz de similaridade resposta
	#group= fator agrupando as distancias
permdisp_mite

anova(permdisp_mite)
 #A significancia pode ser avaliada com a funcao "anova"

plot(permdisp_mite) #Plote as distancias ao centroide 
#agrupando os 3 niveis desse fator: none many few

### Mantel
#Podemos avaliar a hipotese de decaimento de similaridade com os dados funcionais
#Com o conjunto "avi", avalie a hipotese que comunidades ambientalmente similares apresentarao diversidade funcional similar
dis_avi_ambi <-daisy(avi_am,metric="gower") #1 - contrua uma matriz de dissimilaridade de Gower (funcao daisy) com o conjunto "avi_ambi"
dis_fun_avi <- vegdist(FD_avi[,-1],method="euclidian") #2 - Construa uma amtriz de distancia Euclidiana com a matriz de indices funcionais

#Correlacione ambas as matrizes de distancias utilizando o teste de Mantel (funcao "mantel")
mantel(xdis= dis_avi_ambi, ydis= dis_fun_avi)

### Mantel parcial
#E possivel que a mistura de variaveis que descrevem impactos e caracteristicas mais preservadas 
#possa interferir na associacao entre dissimilaridade funcional e em caracteristicas ambientais

avi_ambi_antro <- avi_am[,c(1:4,10)] #Separe o conjunto de variaveis ambientais de "avi" em dois: um com as variaveis antropogenicas e outro com as de vegetacao
avi_ambi_veget <- avi_am[,c(5:9,11)]
dis_avi_antro <- daisy(avi_ambi_antro, metric="gower") #Construa duas matrizes de dissimilaridade de Gower uma para cada tipo de variavel ambiental
dis_avi_veget <- daisy(avi_ambi_veget, metric="gower")

#Correlacione ambas as matrizes de distancias utilizando o teste de Mantel parcial (funcao "mantel.partial")
mantel.partial(xdis= dis_avi_veget, ydis=dis_fun_avi, zdis=dis_avi_antro)


### RDA
#Por vezes temos o objetivo de associar uma matriz resposta com outra matriz preditora
#P.e., podemos avaliar como fatores ambientais influenciam a diversidade funcional de aves.
#Para avaliar esse objetivo podemos utilziar a anÃ¡lise de redundancia (RDA)


#A matriz ambiental (avi_ambi) e composta de fatores, para nao dar problema adiante, transforme-a em 0/1 (dummy) (menos a ultima coluna; utilize a funcao "ifelse")
#Padronize a matriz de indices funcionais ("decostand" argumento "method = "standardize"") para reduzir as diferenÃ§as em escalas dos indices

FD_AVI_pad<- decostand(FD_avi[,-1], method="standardize")
boxplot(FD_AVI_pad)
rda_avi <- rda(FD_AVI_pad, avi_am)
#Construa a RDA (funcao "rda") com a matriz funcional padronizada e a ambiental transformada em dummies

plot(rda_avi)
#Construa um biplot da RDA
#A significancia das restricoes (variabilidade da matriz resposta explicada na RDA; constraints) pode ser avaliada por um teste de permutacao similar a ANOVA (funcao "anova")
